{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digits classification with CNNs\n",
    "\n",
    "In this notebook, we'll train a convolutional neural network (CNN, ConvNet) to classify MNIST digits using Keras.\n",
    "\n",
    "First, the needed imports. Note that there are a few new layers compared to the MLP notebook: Flatten, Convolution2D, MaxPooling2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "nb_classes = 10\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding:\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print()\n",
    "print('MNIST data loaded: train:',len(X_train),'test:',len(X_test))\n",
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('Y_train:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to do a bit of tensor manipulations, depending on the used backend (Theano or Tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a convolutional model.\n",
    "\n",
    "The `Convolution2D` layers operate on 2D matrices so we input the digit images directly to the model.  \n",
    "\n",
    "The `MaxPooling2D` layer reduces the spatial dimensions, that is, makes the image smaller.\n",
    "\n",
    "The `Flatten` layer flattens the 2D matrices into vectors, so we can then switch to  `Dense` layers as in the MLP model. \n",
    "\n",
    "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the CNN model. Note that we do not need the `reshape()` function as in the MLP case. \n",
    "\n",
    "This is a relatively complex model, so training is considerably slower than with MLPs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epoch = 3 # one epoch takes about 80 seconds\n",
    "\n",
    "history = model.fit(X_train, Y_train, nb_epoch=nb_epoch, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['acc'])\n",
    "plt.title('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With enough training epochs, the test accuracy should exceed 99%.  \n",
    "\n",
    "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html).  Even more results can be found [here](http://yann.lecun.com/exdb/mnist/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print()\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "rounded = np.argmax(predictions, axis=1)\n",
    "errors = rounded != y_test\n",
    "nerrors = np.count_nonzero(errors)\n",
    "print('Wrong predictions:', nerrors)\n",
    "\n",
    "maxtoshow = 10\n",
    "print('Showing', maxtoshow, 'first:')\n",
    "ii = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    if ii>=maxtoshow:\n",
    "        break\n",
    "    if errors[i]:\n",
    "        plt.figure(figsize=(1, 1))\n",
    "        plt.axis('off')\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            plt.imshow(X_test[i,0,:,:], cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(X_test[i,:,:,0], cmap=\"gray\")\n",
    "        print(ii,': correct:',y_test[i],'predicted:', rounded[i])\n",
    "        ii = ii + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: train the model in taito-gpu\n",
    "\n",
    "The above model can also be run in taito-gpu in a couple of easy steps:\n",
    "\n",
    "```sh\n",
    "ssh -l USERNAME taito-gpu.csc.fi\n",
    "\n",
    "module purge \n",
    "module load python-env/2.7.10 cuda/8.0\n",
    "    \n",
    "# the following two commands need to be entered only once\n",
    "PYTHONUSERBASE=$USERAPPL/tensorflow.0.11.0 pip install --user /wrk/jppirhon/tensorflow.0.11.0-gcc493_pkg/tensorflow-0.11.0-py2-none-any.whl\n",
    "pip install --user keras h5py Pillow\n",
    "    \n",
    "export PYTHONPATH=$USERAPPL/tensorflow.0.11.0/lib/python2.7/site-packages\n",
    "sbatch /wrk/makoskel/run-python27-gputest.sh /wrk/makoskel/keras-mnist-cnn-taitogpu.py\n",
    "```\n",
    "\n",
    "One epoch should take about 8 seconds.  With 10 epochs, the model should have > 99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
